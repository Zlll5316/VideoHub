import json
import yt_dlp

def scrape_youtube_data():
    # è¿™é‡Œå®šä¹‰æˆ‘ä»¬è¦æœçš„è¯
    queries = [
        "SaaS explainer video animation",
        "App promo video motion graphics"
    ]
    
    all_videos = []
    
    # === å…³é”®è®¾ç½® ===
    # å¦‚æœä½ çš„ä»£ç†ç«¯å£ä¸æ˜¯ 7890ï¼Œè¯·åœ¨è¿™é‡Œä¿®æ”¹ (æ¯”å¦‚æ”¹æˆ 8118)
    # æ ¹æ®ä½ ä¹‹å‰çš„æˆªå›¾ï¼Œæˆ‘ä»¬å…ˆè¯• 7890
    proxy_url = 'http://10.44.254.143:8118'

    ydl_opts = {
        'skip_download': True,       # ä¸ä¸‹è½½è§†é¢‘
        'ignoreerrors': True,        # é‡åˆ°é”™è¯¯ç»§ç»­
        'quiet': True,               # å°‘è¾“å‡ºåºŸè¯
        'no_warnings': True,
        'proxy': proxy_url,          # ä½¿ç”¨ä»£ç†
        'extract_flat': True,        # å¿«é€ŸæŠ“å–æ¨¡å¼
    }

    print("ğŸš€ å¼€å§‹æŠ“å– YouTube æ•°æ®ï¼Œè¯·ç¨ç­‰...")

    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        for query in queries:
            print(f"æ­£åœ¨æœç´¢å…³é”®è¯: {query} ...")
            try:
                # æœå‰ 20 ä¸ª
                search_results = ydl.extract_info(f"ytsearch20:{query}", download=False)
                
                if 'entries' in search_results:
                    for entry in search_results['entries']:
                        if entry:
                            # æ„é€ æˆ‘ä»¬éœ€è¦çš„æ•°æ®æ ¼å¼
                            video_data = {
                                'videoName': entry.get('title'),
                                'videoSource': entry.get('url'),
                                # YouTube å°é¢å›¾é€šå¸¸æ˜¯è¿™ä¸ªæ ¼å¼
                                'coverImage': f"https://i.ytimg.com/vi/{entry.get('id')}/maxresdefault.jpg",
                                'id': entry.get('id'),
                                'duration': entry.get('duration'),
                                'tags': ['SaaS', 'YouTube', 'Animation']
                            }
                            all_videos.append(video_data)
                            print(f"âœ… æŠ“å–åˆ°: {video_data['videoName'][:20]}...")
            except Exception as e:
                print(f"âŒ æœç´¢å‡ºé”™: {e}")

    # ä¿å­˜æ–‡ä»¶
    output_file = 'youtube_data.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(all_videos, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ‰ å¤§åŠŸå‘Šæˆï¼å…±æŠ“å– {len(all_videos)} ä¸ªè§†é¢‘ã€‚")
    print(f"æ•°æ®å·²ä¿å­˜åˆ°å½“å‰ç›®å½•ä¸‹çš„: {output_file}")

if __name__ == "__main__":
    scrape_youtube_data()